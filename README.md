# ğŸ§  Quant_trading_system ğŸ“ˆ

A full-featured modular quantitative trading system powered by:

- ğŸ¤– Reinforcement Learning with PPO / DQN (Stable-Baselines3)
- ğŸ§  High-performance C++ data loader + execution module via PyBind11
- ğŸ§© Custom OpenAI Gym-style trading environment
- ğŸ–¥ï¸ Linux-friendly CLI automation for training & testing
- ğŸ“Š Strategy comparison (DQN vs PPO vs Random baseline)
- ğŸ§ª Integrated test framework for C++ modules and Python models
- ğŸ“¦ TensorBoard logging support for live training monitoring

---

## ğŸ“ Project Structure

```text
Quant_trading_system/
â”œâ”€â”€ train_dqn.py / train_ppo.py         â† RL training entrypoints
â”œâ”€â”€ scripts/                            â† CLI tools
â”‚   â”œâ”€â”€ run_training.sh                 â† One-command training runner
â”‚   â”œâ”€â”€ compare_strategies.py           â† Visualize DQN / PPO / Random
â”‚   â”œâ”€â”€ test_model.py                   â† Evaluate saved models
â”‚   â”œâ”€â”€ test_random.py                  â† Run random baseline
â”‚   â””â”€â”€ test_cpp_module.py              â† Sanity test for cpp_trading.so
â”œâ”€â”€ env/                                â† Gym-style trading environment
â”‚   â”œâ”€â”€ trading_env.py
â”‚   â””â”€â”€ data_loader.py
â”œâ”€â”€ cpp_core/                           â† ğŸ§© C++ backend with PyBind11
â”‚   â”œâ”€â”€ include/                        â† C++ Header files (interfaces)
â”‚   â”‚   â”œâ”€â”€ data_feed.h                 â† DataFeed for OHLCV
â”‚   â”‚   â””â”€â”€ order_executor.hpp          â† Mock order execution logic
â”‚   â”œâ”€â”€ src/                            â† C++ implementations
â”‚   â”‚   â”œâ”€â”€ data_feed.cpp
â”‚   â”‚   â””â”€â”€ order_executor.cpp
â”‚   â”œâ”€â”€ bindings/                       â† Python-C++ interface via PyBind11
â”‚   â”‚   â”œâ”€â”€ data_bindings.cpp
â”‚   â”‚   â”œâ”€â”€ order_bindings.cpp
â”‚   â”‚   â””â”€â”€ main_bindings.cpp           â† PYBIND11_MODULE entry
â”‚   â”œâ”€â”€ build/                          â† Output directory for `cpp_trading.so`
â”‚   â””â”€â”€ CMakeLists.txt                  â† Build instructions using pybind11_add_module
â”œâ”€â”€ models/                             â† Saved RL agent models (PPO / DQN)
â”œâ”€â”€ tensorboard/                        â† Training logs for visualization
â”œâ”€â”€ data/                               â† OHLCV data files (e.g., `SPY_1d.csv`)
â””â”€â”€ README.md                           â† You're here!

âœ… Features Completed
âœ… PPO / DQN reinforcement learning agents

âœ… Random baseline strategy

âœ… Modular training environment using gym.Env

âœ… C++ module integration with PyBind11 (data feed + order execution)

âœ… One-line bash training launcher (run_training.sh)

âœ… Strategy comparison plotting (matplotlib + CSV evaluation)

âœ… C++ module test runner

âœ… TensorBoard log support

ğŸ§ Fully compatible with Linux, WSL2, and macOS


ğŸ› ï¸ Future Work
ğŸ“ˆ Add portfolio metrics (Sharpe Ratio, Win Rate, Max Drawdown)

âš™ï¸ Integrate real-time order execution module in C++

ğŸ§  Add alpha_engine and risk_control strategy modules

ğŸ“ Export full trade logs as CSV

ğŸ” Hyperparameter tuning via Optuna

