import torch
import torch.nn as nn

class ActorCritic(nn.Module):
    def __init__(self, state_dim, action_dim, hidden_dim=128):
        super(ActorCritic, self).__init__()
        print(f"ğŸ“ ActorCritic initialized | state_dim={state_dim}, action_dim={action_dim}")

        self.expected_state_dim = state_dim  # âœ… ä¿å­˜æœŸæœ›çš„ state_dim

        self.shared = nn.Sequential(
            nn.Linear(state_dim, hidden_dim),
            nn.ReLU()
        )
        self.actor = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, action_dim),
            nn.Softmax(dim=-1)
        )
        self.critic = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, 1)
        )

    def forward(self, state):
        # âœ… ç¡®ä¿æ˜¯ tensor
        if not isinstance(state, torch.Tensor):
            state = torch.tensor(state, dtype=torch.float32)

        # âœ… ç¡®ä¿æœ‰ batch ç»´åº¦
        if state.ndim == 1:
            state = state.unsqueeze(0)  # (state_dim,) â (1, state_dim)

        # âœ… æ£€æŸ¥è¾“å…¥ç»´åº¦æ˜¯å¦æ­£ç¡®
        if state.shape[1] != self.expected_state_dim:
            raise ValueError(
                f"âŒ Shape mismatch in ActorCritic.forward: expected {self.expected_state_dim}, "
                f"but got {state.shape[1]}"
            )

        print(f"âš¡ ActorCritic.forward | input shape={state.shape}")

        # Forward pass
        x = self.shared(state)
        action_probs = self.actor(x)
        state_value = self.critic(x)
        return action_probs, state_value



